"""Feature Importance class"""
from itertools import cycle
import numpy as np
import pandas as pd
from functools import partial
from pathos.multiprocessing import Pool

from ...data import DataManager
from .base import BaseGlobalInterpretation
from ...util.plotting import COLORS
from ...util.exceptions import *
from ...model.base import ModelType
from ...util.dataops import divide_zerosafe
from ...util.progressbar import ProgressBar
from ...util.static_types import StaticTypes

from sklearn.metrics import log_loss, mean_absolute_error
from sklearn.utils.multiclass import type_of_target

class Scorer(object):
    def __init__(self, predictions, labels, model_type):
        assert predictions.shape[0] == labels.shape[0], "labels and prediction shapes dont match" \
                                                        "predictions: {0}, labels: {1}".format(predictions.shape,
                                                                                               labels.shape)
        # continuous, binary, continuous multioutput, multiclass, multilabel-indicator
        self.prediction_type = type_of_target(predictions)
        self.label_type = type_of_target(labels)
        self.labels = labels
        self.predictions = predictions
        self.model_type = model_type
    def score(self):
        if self.model_type == StaticTypes.model_types.classifier:
            return log_loss(self.labels, self.predictions)
        elif self.model_type == StaticTypes.model_types.regressor:
            return mean_absolute_error(self.labels, self.predictions)
        else:
            raise ValueError("Model type unknown")

def compute_feature_importance(feature_id, input_data, estimator_fn,
                               original_predictions, feature_info,
                               feature_names, index, training_labels=None,
                               method='output-variance', model_type='regression'):
    """Global function for computing column-wise importance

    Parameters
    ----------
    feature_id: hashable

    input_data:

    estimator_fn: callable

    original_predictions:

    feature_info: dict

    feature_names: array type

    n: int

    Returns
    ----------
    importance: dict
        {feature id: importance value}
    """

    copy_of_data_set = DataManager(input_data.copy(), feature_names=feature_names, index=index)
    n = copy_of_data_set.n_rows

    original_values = copy_of_data_set[feature_id]

    # collect perturbations
    if feature_info[feature_id]['numeric']:
        #data going in: (20, 1)
        # n: 20
        samples = copy_of_data_set.generate_column_sample(feature_id, n_samples=n, strategy='uniform-over-similarity-ranks')
    else:
        samples = copy_of_data_set.generate_column_sample(feature_id, n_samples=n, strategy='random-choice')
    copy_of_data_set[feature_id] = samples.values.reshape(-1)

    new_predictions = estimator_fn(copy_of_data_set.values)

    importance = compute_importance(new_predictions.data,
                                    original_predictions.data,
                                    training_labels,
                                    original_values.data,
                                    samples.data,
                                    method=method,
                                    model_type=model_type)
    return {feature_id: importance}

class FeatureImportance(BaseGlobalInterpretation):
    """Contains methods for feature importance. Subclass of BaseGlobalInterpretation.

    """

    def feature_importance(self, model_instance, ascending=True, filter_classes=None, n_jobs=-1, progressbar=True, n_samples=5000, method='output-variance'):

        """
        Computes feature importance of all features related to a model instance.
        Supports classification, multi-class classification, and regression.

        Wei, Pengfei, Zhenzhou Lu, and Jingwen Song.
        "Variable Importance Analysis: A Comprehensive Review".
        Reliability Engineering & System Safety 142 (2015): 399-432.


        Parameters
        ----------
        model_instance: skater.model.model.Model subtype
            the machine learning model "prediction" function to explain, such that
            predictions = predict_fn(data).
        ascending: boolean, default True
            Helps with ordering Ascending vs Descending
        filter_classes: array type
            The classes to run partial dependence on. Default None invokes all classes.
            Only used in classification models.
        method: string
            How to compute feature importance. performance-decrease requires Interpretation.training_labels
            output-variance: mean absolute value of changes in predictions, given perturbations.
            performance-decrease: difference in log_loss or MAE of training_labels given perturbations.

        Returns
        -------
        importances : Sorted Series


        Examples
        --------
            >>> from skater.model import InMemoryModel
            >>> from skater.core.explanations import Interpretation
            >>> from sklearn.ensemble import RandomForestClassier
            >>> rf = RandomForestClassier()
            >>> rf.fit(X,y)
            >>> model = InMemoryModel(rf, examples = X)
            >>> interpreter = Interpretation()
            >>> interpreter.load_data(X)
            >>> interpreter.feature_importance.feature_importance(model)
        """

        if filter_classes:
            err_msg = "members of filter classes must be" \
                      "members of model_instance.classes." \
                      "Expected members of: {0}\n" \
                      "got: {1}".format(model_instance.target_names,
                                        filter_classes)
            filter_classes = list(filter_classes)
            assert all([i in model_instance.target_names for i in filter_classes]), err_msg

        if method == 'performance-decrease' and self.training_labels is None:
            raise FeatureImportanceError("If interpretation.training_labels are not set, you"
                                         "can only use feature importance methods that do "
                                         "not require ground truth labels")
        elif method == 'performance-decrease':
            training_labels = self.training_labels.data
        else:
            training_labels = None

        if n_samples <= self.data_set.n_rows:
            inputs = self.data_set.generate_sample(strategy='random-choice',
                                                   sample=True,
                                                   n_samples=n_samples)
        else:
            inputs = self.data_set

        original_predictions = model_instance.predict(inputs.data)
        model_type = model_instance.model_type

        if progressbar:
            n_iter = len(self.data_set.feature_ids)
            p = ProgressBar(n_iter, units='features')

        # prep for multiprocessing
        predict_fn = model_instance._get_static_predictor()
        n_jobs = None if n_jobs < 0 else n_jobs
        arg_list = self.data_set.feature_ids
        fi_func = partial(compute_feature_importance,
                          input_data=inputs.data,
                          estimator_fn=predict_fn,
                          original_predictions=original_predictions,
                          feature_info=self.data_set.feature_info,
                          feature_names=self.data_set.feature_ids,
                          index=inputs.index,
                          training_labels=training_labels,
                          method=method,
                          model_type=model_type)

        executor_instance = Pool(n_jobs)
        importances = {}
        try:
            if n_jobs == 1:
                raise ValueError("Skipping to single processing")
            importance_dicts = []
            for importance in executor_instance.map(fi_func, arg_list):
                importance_dicts.append(importance)
                if progressbar:
                    p.animate()
        except:
            self.interpreter.logger.warn("Multiprocessing failed, going single process")
            importance_dicts = []
            for importance in map(fi_func, arg_list):
                importance_dicts.append(importance)
                if progressbar:
                    p.animate()
        finally:
            executor_instance.close()
            executor_instance.join()
            executor_instance.terminate()

        for i in importance_dicts:
            importances.update(i)

        importances = pd.Series(importances).sort_values(ascending=ascending)

        if not importances.sum() > 0:
            self.interpreter.logger.debug("Importances that caused a bug: {}".format(importances))
            raise(FeatureImportanceError("Something went wrong. Importances do not sum to a positive value\n"
                                         "This could be due to:\n"
                                         "1) 0 or infinite divisions\n"
                                         "2) perturbed values == original values\n"
                                         "3) feature is a constant\n"
                                         "Please submit an issue here:\n"
                                         "https://github.com/datascienceinc/Skater/issues"))

        importances = divide_zerosafe(importances, (np.ones(importances.shape[0]) * importances.sum()))
        return importances


    def plot_feature_importance(self, predict_fn, filter_classes=None, ascending=True, ax=None, progressbar=True):
        """Computes feature importance of all features related to a model instance,
        then plots the results. Supports classification, multi-class classification, and regression.

        Parameters
        ----------
        predict_fn: skater.model.model.Model subtype
            estimator "prediction" function to explain the predictive model. Could be probability scores
            or target values
        filter_classes: array type
            The classes to run partial dependence on. Default None invokes all classes.
            Only used in classification models.
        ascending: boolean, default True
            Helps with ordering Ascending vs Descending
        ax: matplotlib.axes._subplots.AxesSubplot
            existing subplot on which to plot feature importance. If none is provided,
            one will be created.

        Returns
        -------
        f: figure instance
        ax: matplotlib.axes._subplots.AxesSubplot
            could be used to for further modification to the plots

        Examples
        --------
            >>> from skater.model import InMemoryModel
            >>> from skater.core.explanations import Interpretation
            >>> from sklearn.ensemble import RandomForestClassier
            >>> rf = RandomForestClassier()
            >>> rf.fit(X,y)
            >>> model = InMemoryModel(rf, examples = X)
            >>> interpreter = Interpretation()
            >>> interpreter.load_data(X)
            >>> interpreter.feature_importance.plot_feature_importance(model, ascending=True, ax=ax)
            """
        try:
            global pyplot
            from matplotlib import pyplot
        except ImportError:
            raise (MatplotlibUnavailableError("Matplotlib is required but unavailable on your system."))
        except RuntimeError:
            raise (MatplotlibDisplayError("Matplotlib unable to open display"))

        importances = self.feature_importance(predict_fn, filter_classes=filter_classes, progressbar=progressbar)

        if ax is None:
            f, ax = pyplot.subplots(1)
        else:
            f = ax.figure

        colors = cycle(COLORS)
        color = next(colors)
        # Below is a weirdness because of how pandas plot is behaving. There might be a better way
        # to resolve the issuse of sorting based on axis
        if ascending is True:
            importances.sort_values(ascending=False).plot(kind='barh', ax=ax, color=color)
        else:
            importances.sort_values(ascending=True).plot(kind='barh', ax=ax, color=color)
        return f, ax

def compute_importance(new_predictions, original_predictions, original_x, perturbed_x,
                       training_labels, method='output-variance', scaled=False,
                       model_type='regression'):
    if method == 'output-variance':
        importance = compute_importance_via_output_variance(np.array(new_predictions),
                                                            np.array(original_predictions),
                                                            np.array(original_x),
                                                            np.array(perturbed_x),
                                                            scaled)
    elif method == 'performance-decrease':
        importance = compute_importance_via_performance_decrease(np.array(new_predictions),
                                                                 np.array(original_predictions),
                                                                 np.array(original_x),
                                                                 np.array(perturbed_x),
                                                                 training_labels,
                                                                 model_type,
                                                                 scaled)

    else:
        raise(KeyError("Unrecongized method for computing feature_importance: {}".format(method)))
    return importance


def compute_importance_via_output_variance(new_predictions, original_predictions,
                                           original_x, perturbed_x, scaled=True):
    """Mean absolute change in predictions given perturbations in a feature"""
    changes_in_predictions = abs(new_predictions - original_predictions)

    if scaled:
        changes_in_predictions = importance_scaler(changes_in_predictions, original_x, perturbed_x)

    importance = np.mean(changes_in_predictions)
    return importance

def compute_importance_via_performance_decrease(new_predictions, original_predictions, training_labels,
                                                original_x, perturbed_x, model_type, scaled=True):

    """Mean absolute error of predictions given perturbations in a feature"""
    scorer1 = Scorer(new_predictions, training_labels.reshape(-1), model_type)
    scorer2 = Scorer(original_predictions, training_labels, model_type)
    score1 = scorer1.score()
    score2 = scorer2.score()

    return abs(min(score2 - score1, 0))

def importance_scaler(values, original_x, perturbed_x):
    raise(NotImplementedError("We currently don't support scaling, we are researching the best"
                              "approaches to do so."))



